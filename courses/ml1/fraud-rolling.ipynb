{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\ttest.csv  tmp  train.csv  train_sample.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/fraud-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** debug parameter set: this is a test run for debugging purposes ***\n",
      "loading train data... 0 100000\n",
      "loading test data...\n",
      "Extracting new features...\n",
      "Extracting aggregation features...\n",
      "Doing rolling std dev of  ['app', 'channel', 'day', 'hour'] ...\n",
      "1.0\n",
      "70000   -999.0\n",
      "70001   -999.0\n",
      "70002   -999.0\n",
      "70003   -999.0\n",
      "70004   -999.0\n",
      "70005   -999.0\n",
      "70006   -999.0\n",
      "70007   -999.0\n",
      "70008   -999.0\n",
      "70009   -999.0\n",
      "Name: rolling, dtype: float32\n",
      "Cumulative count by  ['ip', 'device', 'os'] ...\n",
      "X1 max value =  231\n",
      "Counting unqiue  channel  by  ['ip'] ...\n",
      "X0 max value =  80\n",
      "Counting unqiue  app  by  ['ip'] ...\n",
      "X3 max value =  34\n",
      "Counting unqiue  channel  by  ['app'] ...\n",
      "X6 max value =  32\n",
      "Counting unqiue  app  by  ['ip', 'device', 'os'] ...\n",
      "X8 max value =  22\n",
      "Aggregating by  ['ip', 'day', 'hour'] ...\n",
      "ip_tcount max value =  610\n",
      "Aggregating by  ['ip', 'app'] ...\n",
      "ip_app_count max value =  212\n",
      "Aggregating by  ['ip', 'app', 'os'] ...\n",
      "ip_app_os_count max value =  62\n",
      "Calculating variance of  hour  by  ['ip', 'app', 'os'] ...\n",
      "ip_app_os_var max value =  72.0\n",
      "Doing nextClick...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A non-blending lightGBM model that incorporates portions and ideas from various public kernels.\n",
    "\"\"\"\n",
    "DEBUG = True\n",
    "WHERE = 'kaggle'\n",
    "FILENO = 4\n",
    "NCHUNK = 32000000\n",
    "OFFSET = 75000000\n",
    "VAL_RUN = False\n",
    "\n",
    "MISSING32 = 999999999\n",
    "MISSING8 = 255\n",
    "PUBLIC_CUTOFF = 4032690\n",
    "\n",
    "if WHERE=='kaggle':\n",
    "\tinpath = 'data/fraud-detection/'\n",
    "\tpickle_path ='data/fraud-detection/'\n",
    "\tsuffix = ''\n",
    "\toutpath = ''\n",
    "\tsavepath = ''\n",
    "\toofpath = ''\n",
    "\tcores = 4\n",
    "elif WHERE=='gcloud':\n",
    "\tinpath = '../.kaggle/competitions/talkingdata-adtracking-fraud-detection/'\n",
    "\tpickle_path = '../data/'\n",
    "\tsuffix = '.zip'\n",
    "\toutpath = '../sub/'\n",
    "\toofpath = '../oof/'\n",
    "\tsavepath = '../data/'\n",
    "\tcores = 7\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def do_rollingstd(df, group_cols, agg_name, agg_type='float32', window_size=5, show_max=False, show_agg=True):\n",
    "    # suggest trying ['app', 'channel', 'day', 'hour'] to start\n",
    "    if show_agg:\n",
    "        print( \"Doing rolling std dev of \", group_cols , '...')\n",
    "    c_gp = df[group_cols].groupby(group_cols).size().rename('gp_count').to_frame().reset_index()\n",
    "    df = df.merge(c_gp, on=group_cols, how='left')\n",
    "    del c_gp\n",
    "    df['ma_gp'] = df[group_cols+['gp_count']].groupby(group_cols)['gp_count'].unique().\\\n",
    "    rolling(window_size).mean().rename('ma_gp').to_frame().reset_index(drop=True)\n",
    "    df['res'] = df['gp_count'] - df['ma_gp'] #might need to use sub method here to deal with subtraction of NAs\n",
    "    df.drop(['ma_gp', 'gp_count'], axis=1, inplace=True)\n",
    "    gc.collect()\n",
    "    df[agg_name] = df[group_cols+['res']].groupby(group_cols)['res'].rolling(window_size).\\\n",
    "    std().rename(agg_name).to_frame().reset_index(drop=True)\n",
    "    df[agg_name].fillna(-999, inplace=True)\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    print(df[agg_name].notnull().mean())\n",
    "    print(df[agg_name].iloc[70000:70010])\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "    \n",
    "def do_count( df, group_cols, agg_name, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Aggregating by \", group_cols , '...' )\n",
    "    gp = df[group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "\n",
    "def do_countuniq( df, group_cols, counted, agg_name, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Counting unqiue \", counted, \" by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "    \n",
    "def do_cumcount( df, group_cols, counted, agg_name, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Cumulative count by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].cumcount()\n",
    "    df[agg_name]=gp.values\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "\n",
    "def do_mean( df, group_cols, counted, agg_name, agg_type='float32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Calculating mean of \", counted, \" by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].mean().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "\n",
    "def do_var( df, group_cols, counted, agg_name, agg_type='float32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Calculating variance of \", counted, \" by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].var().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "\n",
    "debug = DEBUG\n",
    "if debug:\n",
    "    print('*** debug parameter set: this is a test run for debugging purposes ***')\n",
    "\n",
    "    \n",
    "if VAL_RUN:\n",
    "    nrows=122071522\n",
    "    outpath = oofpath\n",
    "else:\n",
    "    nrows=184903890\n",
    "nchunk=NCHUNK\n",
    "val_size=2500000\n",
    "frm=nrows-OFFSET\n",
    "if debug:\n",
    "    frm=0\n",
    "    nchunk=100000\n",
    "    val_size=10000\n",
    "to=frm+nchunk\n",
    "fileno = FILENO\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32',\n",
    "        }\n",
    "\n",
    "if VAL_RUN:\n",
    "    print('loading train data...',frm,to)\n",
    "    train_df = pd.read_pickle( pickle_path+\"training.pkl.gz\" )[frm:to]\n",
    "    train_df['click_time'] = pd.to_datetime( train_df.click_time )\n",
    "    print('loading test data...')\n",
    "    if debug:\n",
    "        public_cutoff = 10000\n",
    "        test_df = pd.read_pickle( pickle_path+\"validation.pkl.gz\" )[:30000]\n",
    "        test_df['click_time'] = pd.to_datetime( test_df.click_time )\n",
    "        y_test = test_df['is_attributed'].values\n",
    "        test_df.drop(['is_attributed'],axis=1,inplace=True)\n",
    "    else:\n",
    "        public_cutoff = PUBLIC_CUTOFF\n",
    "        test_df = pd.read_pickle( pickle_path+\"validation.pkl.gz\" )\n",
    "        test_df['click_time'] = pd.to_datetime( test_df.click_time )\n",
    "        y_test = test_df['is_attributed'].values\n",
    "        test_df.drop(['is_attributed'],axis=1,inplace=True)\n",
    "else:\n",
    "    print('loading train data...',frm,to)\n",
    "    train_df = pd.read_csv(inpath+\"train.csv\", parse_dates=['click_time'], skiprows=range(1,frm), nrows=to-frm, dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n",
    "    print('loading test data...')\n",
    "    if debug:\n",
    "        test_df = pd.read_csv(inpath+\"test.csv\", nrows=100000, parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    else:\n",
    "        test_df = pd.read_csv(inpath+\"test.csv\", parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    train_df['click_id'] = MISSING32\n",
    "    train_df['click_id'] = train_df.click_id.astype('uint32')\n",
    "\n",
    "\n",
    "len_train = len(train_df)\n",
    "test_df['is_attributed'] = MISSING8\n",
    "test_df['is_attributed'] = test_df.is_attributed.astype('uint8')\n",
    "train_df=train_df.append(test_df)\n",
    "\n",
    "del test_df\n",
    "gc.collect()\n",
    "\n",
    "print('Extracting new features...')\n",
    "train_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('uint8')\n",
    "train_df['day'] = pd.to_datetime(train_df.click_time).dt.day.astype('uint8')\n",
    "\n",
    "print('Extracting aggregation features...')\n",
    "\n",
    "train_df = do_rollingstd(train_df, ['day', 'hour'], 'rolling', window_size=5, show_max=False, show_agg=True); gc.collect()\n",
    "train_df = do_cumcount( train_df, ['ip', 'device', 'os'], 'app', 'X1', show_max=True ); gc.collect()\n",
    "#train_df = do_cumcount( train_df, ['ip'], 'os', 'X7', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip'], 'channel', 'X0', 'uint8', show_max=True ); gc.collect()\n",
    "#train_df = do_countuniq( train_df, ['ip', 'day'], 'hour', 'X2', 'uint8', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip'], 'app', 'X3', 'uint8', show_max=True ); gc.collect()\n",
    "#train_df = do_countuniq( train_df, ['ip', 'app'], 'os', 'X4', 'uint8', show_max=True ); gc.collect()\n",
    "#train_df = do_countuniq( train_df, ['ip'], 'device', 'X5', 'uint16', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['app'], 'channel', 'X6', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip', 'device', 'os'], 'app', 'X8', show_max=True ); gc.collect()\n",
    "train_df = do_count( train_df, ['ip', 'day', 'hour'], 'ip_tcount', show_max=True ); gc.collect()\n",
    "train_df = do_count( train_df, ['ip', 'app'], 'ip_app_count', show_max=True ); gc.collect()\n",
    "train_df = do_count( train_df, ['ip', 'app', 'os'], 'ip_app_os_count', 'uint16', show_max=True ); gc.collect()\n",
    "#train_df = do_var( train_df, ['ip', 'day', 'channel'], 'hour', 'ip_tchan_count', show_max=True ); gc.collect()\n",
    "train_df = do_var( train_df, ['ip', 'app', 'os'], 'hour', 'ip_app_os_var', show_max=True ); gc.collect()\n",
    "#train_df = do_var( train_df, ['ip', 'app', 'channel'], 'day', 'ip_app_channel_var_day', show_max=True ); gc.collect()\n",
    "#train_df = do_mean( train_df, ['ip', 'app', 'channel'], 'hour', 'ip_app_channel_mean_hour', show_max=True ); gc.collect()\n",
    "\n",
    "print('Doing nextClick...')\n",
    "predictors=[]\n",
    "new_feature = 'nextClick'\n",
    "D=2**26\n",
    "train_df['category'] = (train_df['ip'].astype(str) + \"_\" + train_df['app'].astype(str) + \"_\" + train_df['device'].astype(str) \\\n",
    "        + \"_\" + train_df['os'].astype(str)).apply(hash) % D\n",
    "click_buffer= np.full(D, 3000000000, dtype=np.uint32)\n",
    "train_df['epochtime']= train_df['click_time'].astype(np.int64) // 10 ** 9\n",
    "next_clicks= []\n",
    "for category, t in zip(reversed(train_df['category'].values), reversed(train_df['epochtime'].values)):\n",
    "    next_clicks.append(click_buffer[category]-t)\n",
    "    click_buffer[category]= t\n",
    "del(click_buffer)\n",
    "QQ= list(reversed(next_clicks))\n",
    "train_df.drop(['epochtime','category','click_time'], axis=1, inplace=True)\n",
    "train_df[new_feature] = pd.Series(QQ).astype('float32')\n",
    "predictors.append(new_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 1)\n",
      "('b', 1)\n",
      "('a', 1)\n",
      "('b', 2)\n",
      "('b', 2)\n",
      "('a', 2)\n",
      "('b', 2)\n"
     ]
    }
   ],
   "source": [
    "hr =[1,1,1,2,2,2,2]\n",
    "id = ['a', 'b', 'a', 'b', 'b', 'a', 'b']\n",
    "for i in zip(id, hr):\n",
    "    print(i)\n",
    "df = pd.DataFrame(zip(id, hr), columns = ['id', 'hr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index   0\n",
      "0    id  hr\n",
      "1     a   1\n",
      "2     b   1\n",
      "3     a   1\n",
      "4     b   2\n",
      "5     b   2\n",
      "6     a   2\n",
      "7     b   2\n"
     ]
    }
   ],
   "source": [
    "data = np.array([['id','hr'],\n",
    "                ['a', 1],\n",
    "                ['b', 1],\n",
    "                ['a', 1],\n",
    "                ['b', 2],\n",
    "                ['b', 2],\n",
    "                ['a', 2],\n",
    "                ['b', 2]\n",
    "                ])\n",
    "                \n",
    "print(pd.DataFrame(data=data[:,1:],\n",
    "                  index=data[:,0],\n",
    "                  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "data = OrderedDict([ ('id', ['a', 'b', 'a', 'b', 'b', 'a', 'b']),\n",
    "          ('hr', [1, 1, 1, 2, 2, 2, 2])\n",
    "           ] )\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  hr\n",
       "0  a   1\n",
       "1  b   1\n",
       "2  a   1\n",
       "3  b   2\n",
       "4  b   2\n",
       "5  a   2\n",
       "6  b   2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_rollingstd(df, group_cols, agg_name, agg_type='float32', window_size=5, show_max=False, show_agg=True):\n",
    "    # suggest trying ['app', 'channel', 'day', 'hour'] to start\n",
    "    if show_agg:\n",
    "        print( \"Doing rolling std dev of \", group_cols , '...')\n",
    "    c_gp = df[group_cols].groupby(group_cols).size().rename('gp_count').to_frame().reset_index()\n",
    "    df = df.merge(c_gp, on=group_cols, how='left')\n",
    "    del c_gp\n",
    "    df['ma_gp'] = df[group_cols+['gp_count']].groupby(group_cols)['gp_count'].mean().\\\n",
    "    rolling(window_size).sum().rename('ma_gp').to_frame().reset_index(drop=True)\n",
    "    df['res'] = df['gp_count'] - df['ma_gp'] #might need to use sub method here to deal with subtraction of NAs\n",
    "    #df.drop(['ma_gp', 'gp_count'], axis=1, inplace=True)\n",
    "    gc.collect()\n",
    "    df[agg_name] = df[group_cols+['res']].groupby(group_cols)['res'].rolling(window_size).\\\n",
    "    std().rename(agg_name).to_frame().reset_index(drop=True)\n",
    "    df[agg_name].fillna(-999, inplace=True)\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    print(df[agg_name].notnull().mean())\n",
    "    print(df[agg_name].iloc[70000:70010])\n",
    "    gc.collect()\n",
    "    return( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing rolling std dev of  ['id', 'hr'] ...\n",
      "1.0\n",
      "Series([], Name: rolling, dtype: float32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hr</th>\n",
       "      <th>gp_count</th>\n",
       "      <th>ma_gp</th>\n",
       "      <th>res</th>\n",
       "      <th>rolling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  hr  gp_count  ma_gp  res  rolling\n",
       "0  a   1         2    NaN  NaN   -999.0\n",
       "1  b   1         1    3.0 -2.0   -999.0\n",
       "2  a   1         2    2.0  0.0   -999.0\n",
       "3  b   2         3    4.0 -1.0   -999.0\n",
       "4  b   2         3    NaN  NaN   -999.0\n",
       "5  a   2         1    NaN  NaN   -999.0\n",
       "6  b   2         3    NaN  NaN   -999.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_rollingstd(df, ['id', 'hr'], 'rolling', agg_type='float32', window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols=['id', 'hr']\n",
    "agg_name = 'rolling'\n",
    "agg_type='float32'\n",
    "window_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hr</th>\n",
       "      <th>gp_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  hr  gp_count\n",
       "0  a   1         2\n",
       "1  b   1         1\n",
       "2  a   1         2\n",
       "3  b   2         3\n",
       "4  b   2         3\n",
       "5  a   2         1\n",
       "6  b   2         3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_gp = df[group_cols].groupby(group_cols).size().rename('gp_count').to_frame().reset_index()\n",
    "df = df.merge(c_gp, on=group_cols, how='left')\n",
    "del c_gp\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hr</th>\n",
       "      <th>gp_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  hr  gp_count\n",
       "0  a   1         2\n",
       "1  b   1         1\n",
       "3  b   2         3\n",
       "5  a   2         1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[group_cols+['gp_count']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[group_cols+['gp_count']].drop_duplicates()\n",
    "df2['ma']=df2.groupby('id')['gp_count'].rolling(2).sum().reset_index(0,drop=True)\n",
    "#.groupby(group_cols)['gp_count'].unique()#.reset_index(drop=True)#.\\\n",
    "    #rolling(window_size).sum().rename('ma_gp').to_frame().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hr</th>\n",
       "      <th>gp_count_x</th>\n",
       "      <th>gp_count_y</th>\n",
       "      <th>ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  hr  gp_count_x  gp_count_y   ma\n",
       "0  a   1           2           2  NaN\n",
       "1  b   1           1           1  NaN\n",
       "2  a   1           2           2  NaN\n",
       "3  b   2           3           3  4.0\n",
       "4  b   2           3           3  4.0\n",
       "5  a   2           1           1  3.0\n",
       "6  b   2           3           3  4.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.merge(df2, on=group_cols, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "data = OrderedDict([ ('id', ['a', 'b', 'a', 'b', 'b', 'a', 'b', 'a', 'b']),\n",
    "          ('hr', [1, 1, 1, 2, 2, 2, 2, 3, 3])\n",
    "           ] )\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  hr\n",
       "0  a   1\n",
       "1  b   1\n",
       "2  a   1\n",
       "3  b   2\n",
       "4  b   2\n",
       "5  a   2\n",
       "6  b   2\n",
       "7  a   3\n",
       "8  b   3"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols=['id', 'hr']\n",
    "agg_name = 'rolling'\n",
    "agg_type='float32'\n",
    "window_size=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hr</th>\n",
       "      <th>gp_count</th>\n",
       "      <th>rolling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  hr  gp_count   rolling\n",
       "0  a   1         2       NaN\n",
       "1  b   1         1       NaN\n",
       "2  a   1         2       NaN\n",
       "3  b   2         3       NaN\n",
       "4  b   2         3       NaN\n",
       "5  a   2         1       NaN\n",
       "6  b   2         3       NaN\n",
       "7  a   3         1  0.353553\n",
       "8  b   3         1  0.000000"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_gp = df[group_cols].groupby(group_cols).size().rename('gp_count').to_frame().reset_index()\n",
    "df = df.merge(c_gp, on=group_cols, how='left')\n",
    "del c_gp\n",
    "gc.collect()\n",
    "df2 = df[group_cols+['gp_count']].drop_duplicates()\n",
    "df2['ma']=df2.groupby('id')['gp_count'].rolling(2).mean().reset_index(0,drop=True)\n",
    "df2['res'] = df2['gp_count'] - df2['ma']\n",
    "df2.drop(['gp_count', 'res'], axis=1, inplace=True)\n",
    "df2[agg_name]=df2.groupby('id')['ma'].rolling(2).std().reset_index(0,drop=True)\n",
    "df2.drop('ma', axis=1, inplace=True)\n",
    "df = df.merge(df2, on=group_cols, how='left')\n",
    "del df2\n",
    "gc.collect()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** debug parameter set: this is a test run for debugging purposes ***\n",
      "loading train data... 0 100000\n",
      "loading test data...\n",
      "Extracting new features...\n",
      "Extracting aggregation features...\n",
      "Doing rolling std dev of  ['channel', 'hour'] ...\n",
      "rolling max value =  1078.337841309485\n",
      "10872\n",
      "           rolling  channel  hour\n",
      "0              NaN      379    14\n",
      "1              NaN      379    14\n",
      "2              NaN      379    14\n",
      "4              NaN      379    14\n",
      "5              NaN      379    14\n",
      "6              NaN      379    14\n",
      "7              NaN      379    14\n",
      "8              NaN      379    14\n",
      "10             NaN      379    14\n",
      "11             NaN      379    14\n",
      "12             NaN      379    14\n",
      "13             NaN      379    14\n",
      "14             NaN      379    14\n",
      "15             NaN      379    14\n",
      "16             NaN      379    14\n",
      "17             NaN      379    14\n",
      "18             NaN      379    14\n",
      "19             NaN      379    14\n",
      "20             NaN      379    14\n",
      "21             NaN      379    14\n",
      "23             NaN      379    14\n",
      "24             NaN      379    14\n",
      "25             NaN      379    14\n",
      "26             NaN      379    14\n",
      "27             NaN      379    14\n",
      "28             NaN      379    14\n",
      "29             NaN      379    14\n",
      "30             NaN      379    14\n",
      "31             NaN      379    14\n",
      "32             NaN      379    14\n",
      "...            ...      ...   ...\n",
      "199108  778.524566      379     4\n",
      "199165  778.524566      379     4\n",
      "199177  778.524566      379     4\n",
      "199178  778.524566      379     4\n",
      "199180  778.524566      379     4\n",
      "199209  778.524566      379     4\n",
      "199248  778.524566      379     4\n",
      "199250  778.524566      379     4\n",
      "199274  778.524566      379     4\n",
      "199296  778.524566      379     4\n",
      "199316  778.524566      379     4\n",
      "199405  778.524566      379     4\n",
      "199449  778.524566      379     4\n",
      "199453  778.524566      379     4\n",
      "199475  778.524566      379     4\n",
      "199495  778.524566      379     4\n",
      "199505  778.524566      379     4\n",
      "199558  778.524566      379     4\n",
      "199601  778.524566      379     4\n",
      "199610  778.524566      379     4\n",
      "199614  778.524566      379     4\n",
      "199676  778.524566      379     4\n",
      "199690  778.524566      379     4\n",
      "199699  778.524566      379     4\n",
      "199766  778.524566      379     4\n",
      "199840  778.524566      379     4\n",
      "199855  778.524566      379     4\n",
      "199987  778.524566      379     4\n",
      "199993  778.524566      379     4\n",
      "199998  778.524566      379     4\n",
      "\n",
      "[3908 rows x 3 columns]\n",
      "Cumulative count by  ['ip', 'device', 'os'] ...\n",
      "X1 max value =  231\n",
      "Counting unqiue  channel  by  ['ip'] ...\n",
      "X0 max value =  80\n",
      "Counting unqiue  app  by  ['ip'] ...\n",
      "X3 max value =  34\n",
      "Counting unqiue  channel  by  ['app'] ...\n",
      "X6 max value =  32\n",
      "Counting unqiue  app  by  ['ip', 'device', 'os'] ...\n",
      "X8 max value =  22\n",
      "Aggregating by  ['ip', 'day', 'hour'] ...\n",
      "ip_tcount max value =  610\n",
      "Aggregating by  ['ip', 'app'] ...\n",
      "ip_app_count max value =  212\n",
      "Aggregating by  ['ip', 'app', 'os'] ...\n",
      "ip_app_os_count max value =  62\n",
      "Calculating variance of  hour  by  ['ip', 'app', 'os'] ...\n",
      "ip_app_os_var max value =  72.0\n",
      "Doing nextClick...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A non-blending lightGBM model that incorporates portions and ideas from various public kernels.\n",
    "\"\"\"\n",
    "DEBUG = True\n",
    "WHERE = 'kaggle'\n",
    "FILENO = 4\n",
    "NCHUNK = 32000000\n",
    "OFFSET = 75000000\n",
    "VAL_RUN = False\n",
    "\n",
    "MISSING32 = 999999999\n",
    "MISSING8 = 255\n",
    "PUBLIC_CUTOFF = 4032690\n",
    "\n",
    "if WHERE=='kaggle':\n",
    "\tinpath = 'data/fraud-detection/'\n",
    "\tpickle_path ='data/fraud-detection/'\n",
    "\tsuffix = ''\n",
    "\toutpath = ''\n",
    "\tsavepath = ''\n",
    "\toofpath = ''\n",
    "\tcores = 4\n",
    "elif WHERE=='gcloud':\n",
    "\tinpath = '../.kaggle/competitions/talkingdata-adtracking-fraud-detection/'\n",
    "\tpickle_path = '../data/'\n",
    "\tsuffix = '.zip'\n",
    "\toutpath = '../sub/'\n",
    "\toofpath = '../oof/'\n",
    "\tsavepath = '../data/'\n",
    "\tcores = 7\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def do_rollingstd(df, group_cols, agg_name, agg_type='float32', window_size=5, show_max=False, show_agg=True):\n",
    "    # suggest trying ['app', 'channel', 'day', 'hour'] to start\n",
    "    if show_agg:\n",
    "        print( \"Doing rolling std dev of \", group_cols , '...')\n",
    "    c_gp = df[group_cols].groupby(group_cols).size().rename('gp_count').to_frame().reset_index()\n",
    "    df = df.merge(c_gp, on=group_cols, how='left')\n",
    "    del c_gp\n",
    "    gc.collect()\n",
    "    df2 = df[group_cols+['gp_count']].drop_duplicates()\n",
    "    df2['ma']=df2.groupby('channel')['gp_count'].rolling(2).mean().reset_index(0,drop=True)\n",
    "    df2['res'] = df2['gp_count'] - df2['ma']\n",
    "    df2.drop(['gp_count', 'res'], axis=1, inplace=True)\n",
    "    df2[agg_name]=df2.groupby('channel')['ma'].rolling(2).std().reset_index(0,drop=True)\n",
    "    df2.drop('ma', axis=1, inplace=True)\n",
    "    df = df.merge(df2, on=group_cols, how='left')\n",
    "    del df2\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    gc.collect()\n",
    "    #print(df[agg_name].count())\n",
    "    #print(df[[agg_name]+['channel', 'hour']][df['channel']==379])#.iloc[60000:60010])\n",
    "    df[agg_name].fillna(-999, inplace=True)\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return(df)\n",
    "    \n",
    "\n",
    "debug = DEBUG\n",
    "if debug:\n",
    "    print('*** debug parameter set: this is a test run for debugging purposes ***')\n",
    "\n",
    "    \n",
    "if VAL_RUN:\n",
    "    nrows=122071522\n",
    "    outpath = oofpath\n",
    "else:\n",
    "    nrows=184903890\n",
    "nchunk=NCHUNK\n",
    "val_size=2500000\n",
    "frm=nrows-OFFSET\n",
    "if debug:\n",
    "    frm=0\n",
    "    nchunk=100000\n",
    "    val_size=10000\n",
    "to=frm+nchunk\n",
    "fileno = FILENO\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32',\n",
    "        }\n",
    "\n",
    "if VAL_RUN:\n",
    "    print('loading train data...',frm,to)\n",
    "    train_df = pd.read_pickle( pickle_path+\"training.pkl.gz\" )[frm:to]\n",
    "    train_df['click_time'] = pd.to_datetime( train_df.click_time )\n",
    "    print('loading test data...')\n",
    "    if debug:\n",
    "        public_cutoff = 10000\n",
    "        test_df = pd.read_pickle( pickle_path+\"validation.pkl.gz\" )[:30000]\n",
    "        test_df['click_time'] = pd.to_datetime( test_df.click_time )\n",
    "        y_test = test_df['is_attributed'].values\n",
    "        test_df.drop(['is_attributed'],axis=1,inplace=True)\n",
    "    else:\n",
    "        public_cutoff = PUBLIC_CUTOFF\n",
    "        test_df = pd.read_pickle( pickle_path+\"validation.pkl.gz\" )\n",
    "        test_df['click_time'] = pd.to_datetime( test_df.click_time )\n",
    "        y_test = test_df['is_attributed'].values\n",
    "        test_df.drop(['is_attributed'],axis=1,inplace=True)\n",
    "else:\n",
    "    print('loading train data...',frm,to)\n",
    "    train_df = pd.read_csv(inpath+\"train.csv\", parse_dates=['click_time'], skiprows=range(1,frm), nrows=to-frm, dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n",
    "    print('loading test data...')\n",
    "    if debug:\n",
    "        test_df = pd.read_csv(inpath+\"test.csv\", nrows=100000, parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    else:\n",
    "        test_df = pd.read_csv(inpath+\"test.csv\", parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    train_df['click_id'] = MISSING32\n",
    "    train_df['click_id'] = train_df.click_id.astype('uint32')\n",
    "\n",
    "\n",
    "len_train = len(train_df)\n",
    "test_df['is_attributed'] = MISSING8\n",
    "test_df['is_attributed'] = test_df.is_attributed.astype('uint8')\n",
    "train_df=train_df.append(test_df)\n",
    "\n",
    "del test_df\n",
    "gc.collect()\n",
    "\n",
    "print('Extracting new features...')\n",
    "train_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('uint8')\n",
    "train_df['day'] = pd.to_datetime(train_df.click_time).dt.day.astype('uint8')\n",
    "\n",
    "print('Extracting aggregation features...')\n",
    "\n",
    "train_df = do_rollingstd(train_df, ['channel', 'hour'], 'rolling', window_size=3, show_max=True, show_agg=True); gc.collect()\n",
    "train_df = do_cumcount( train_df, ['ip', 'device', 'os'], 'app', 'X1', show_max=True ); gc.collect()\n",
    "#train_df = do_cumcount( train_df, ['ip'], 'os', 'X7', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip'], 'channel', 'X0', 'uint8', show_max=True ); gc.collect()\n",
    "#train_df = do_countuniq( train_df, ['ip', 'day'], 'hour', 'X2', 'uint8', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip'], 'app', 'X3', 'uint8', show_max=True ); gc.collect()\n",
    "#train_df = do_countuniq( train_df, ['ip', 'app'], 'os', 'X4', 'uint8', show_max=True ); gc.collect()\n",
    "#train_df = do_countuniq( train_df, ['ip'], 'device', 'X5', 'uint16', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['app'], 'channel', 'X6', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip', 'device', 'os'], 'app', 'X8', show_max=True ); gc.collect()\n",
    "train_df = do_count( train_df, ['ip', 'day', 'hour'], 'ip_tcount', show_max=True ); gc.collect()\n",
    "train_df = do_count( train_df, ['ip', 'app'], 'ip_app_count', show_max=True ); gc.collect()\n",
    "train_df = do_count( train_df, ['ip', 'app', 'os'], 'ip_app_os_count', 'uint16', show_max=True ); gc.collect()\n",
    "#train_df = do_var( train_df, ['ip', 'day', 'channel'], 'hour', 'ip_tchan_count', show_max=True ); gc.collect()\n",
    "train_df = do_var( train_df, ['ip', 'app', 'os'], 'hour', 'ip_app_os_var', show_max=True ); gc.collect()\n",
    "#train_df = do_var( train_df, ['ip', 'app', 'channel'], 'day', 'ip_app_channel_var_day', show_max=True ); gc.collect()\n",
    "#train_df = do_mean( train_df, ['ip', 'app', 'channel'], 'hour', 'ip_app_channel_mean_hour', show_max=True ); gc.collect()\n",
    "\n",
    "print('Doing nextClick...')\n",
    "predictors=[]\n",
    "new_feature = 'nextClick'\n",
    "D=2**26\n",
    "train_df['category'] = (train_df['ip'].astype(str) + \"_\" + train_df['app'].astype(str) + \"_\" + train_df['device'].astype(str) \\\n",
    "        + \"_\" + train_df['os'].astype(str)).apply(hash) % D\n",
    "click_buffer= np.full(D, 3000000000, dtype=np.uint32)\n",
    "train_df['epochtime']= train_df['click_time'].astype(np.int64) // 10 ** 9\n",
    "next_clicks= []\n",
    "for category, t in zip(reversed(train_df['category'].values), reversed(train_df['epochtime'].values)):\n",
    "    next_clicks.append(click_buffer[category]-t)\n",
    "    click_buffer[category]= t\n",
    "del(click_buffer)\n",
    "QQ= list(reversed(next_clicks))\n",
    "train_df.drop(['epochtime','category','click_time'], axis=1, inplace=True)\n",
    "train_df[new_feature] = pd.Series(QQ).astype('float32')\n",
    "predictors.append(new_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
